{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1707999846275,"sparkVersion":"3.5.0","uid":"Tokenizer_ccdc525b7a81","paramMap":{"outputCol":"words1","inputCol":"free_text"},"defaultParamMap":{"outputCol":"Tokenizer_ccdc525b7a81__output"}}
